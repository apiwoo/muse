Project MUSE: High-Fidelity Tri-Core Engine (V5)

핵심 철학 (Core Philosophy)
"Zero Compromise on Accuracy"

속도 개선을 위해 입력 해상도를 줄이거나(Downscaling) 화질을 희생하지 않음.

모든 Segmentation 모델은 Native 1080p (FHD) 해상도에서 구동하여 머리카락 한 올의 디테일까지 보존함.

엔진 파이프라인: "The Guided High-Res Flow"
graph TD
Input[Camera Input 1080p] --> ViTPose[ViTPose TensorRT]
Input --> DeepLab[DeepLabV3+ (1080p)]
Input --> MODNet[MODNet (1080p)]

ViTPose -->|Bone Coordinates| Skeleton[Spatial Anchor]
Skeleton -->|Valid Hull Mask| Consensus

DeepLab -->|Semantic Mask| Consensus
MODNet -->|Alpha Matte| Consensus

Consensus[Tri-Core Logic] -->|High-Res Alpha| FinalMask

Input --> Warper[Morphing Engine]
Skeleton --> Warper
FinalMask --> Warper

Warper --> HoleFilling[Smart In-painting]
BackgroundBuffer --> HoleFilling

HoleFilling --> Output[Broadcast Output]

상세 기술 명세

A. High-Fidelity Model Inference (고정밀 추론)
모든 Segmentation 모델은 TensorRT의 Dynamic Shape 기능을 사용하여 1920x1080 입력을 직접 처리함.

MODNet (Detailer):

Input: 1920x1080 (Native)

Optimization: FP16 (Half Precision)만 적용, 해상도는 유지.

역할: 고해상도 Alpha Matting을 통해 머리카락, 옷 주름 등의 디테일 보존.

DeepLabV3+ (Validator):

Input: 1920x1080 (Native)

역할: 고해상도에서도 객체(사람)와 배경을 정확히 분리.

ViTPose (Guide):

Input: 256x192 (Pose estimation standard)

Output: 1080p 좌표계로 Upscaling된 정밀 좌표.

역할: Spatial Anchor. ViTPose가 감지한 뼈대 영역(Hull) 밖의 모든 픽셀은 배경으로 강제 할당 (노이즈 0%).

B. 성형 및 배경 복원 (Morphing & Healing)
고해상도 마스크를 사용하여 성형 시 경계선이 깨지거나 계단 현상(Aliasing)이 생기는 것을 방지.

Warping (성형):

1080p 마스크와 원본 이미지를 동기화하여 변형.

Hole Filling (빈 공간 채우기):

성형으로 이동한 픽셀의 뒷공간을 Background_Buffer에서 복원.

경계면은 Poisson Blending 또는 Gaussian Feathering으로 자연스럽게 처리.

C. 적응형 배경 업데이트 (Adaptive Background)

초기화: B 키 입력 시 1080p 배경 버퍼 생성.

적응형 로직:

Tri-Core가 "확실한 배경"이라고 합의한 영역(1080p Pixel-wise check)에 한해, 배경 버퍼를 현재 프레임 값으로 미세 업데이트 (Learning Rate: 0.005).

조명 변화에 부드럽게 대응.

구현 로드맵 (Action Plan)

Step 1: 고정밀 TensorRT 변환기 (tools/convert_models_to_trt.py)

기능: MODNet, DeepLabV3+ 등의 ONNX 모델을 1920x1080 해상도에 최적화된 TensorRT 엔진으로 변환.

설정: min=(1,3,512,512), opt=(1,3,1080,1920), max=(1,3,1080,1920) 프로파일 적용.

Step 2: 통합 추론 모듈 (src/ai/consensus_engine.py)

3개 모델 병렬 로딩 및 동기화.

ViTPose 가이드를 적용한 최종 마스크 합성 로직 구현.

Step 3: 적응형 배경 버퍼 (src/graphics/adaptive_bg.py)

배경 업데이트 및 Hole Filling 커널 구현.

Step 4: 메인 통합

run_muse.py에서 학습 로직을 제거하고 이 새로운 파이프라인으로 연결.

하드웨어 요구 사항

VRAM: 1080p 모델 2개(MODNet, DeepLab) + ViTPose 로드 시 약 6~8GB 예상. (RTX 3060 12GB 안전함)

속도: FP16 가속 필수. (30fps 방어 목표, 미달 시 1080p 유지하되 DeepLab만 경량화 고려)