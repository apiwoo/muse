# Project MUSE - convert_student_to_trt.py
# Target: Convert Student Model (ResNet-34 U-Net) to TensorRT Engine
# Resolution: 960x544 (High-Fidelity)
# (C) 2025 MUSE Corp. All rights reserved.

import os
import sys
import torch
import torch.onnx
import tensorrt as trt

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.ai.distillation.student.model_arch import MuseStudentModel

# [High-Fidelity Resolution Config]
# Width: 960, Height: 544
TARGET_W = 960
TARGET_H = 544

def export_onnx(pth_path, onnx_path):
    print(f"ðŸš€ [Step 1] PyTorch -> ONNX ë³€í™˜ ì‹œìž‘... (Res: {TARGET_W}x{TARGET_H})")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = MuseStudentModel(num_keypoints=17).to(device)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    if not os.path.exists(pth_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pth_path}")
        print("   -> ë¨¼ì € 'tools/train_student.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        sys.exit(1)
        
    try:
        state_dict = torch.load(pth_path, map_location=device)
        model.load_state_dict(state_dict)
        model.eval()
        print("   âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # ë”ë¯¸ ìž…ë ¥ (Batch:1, Channel:3, Height:544, Width:960)
    # ì£¼ì˜: PyTorchëŠ” (N, C, H, W) ìˆœì„œìž…ë‹ˆë‹¤.
    dummy_input = torch.randn(1, 3, TARGET_H, TARGET_W).to(device)
    
    try:
        torch.onnx.export(
            model,
            dummy_input,
            onnx_path,
            input_names=['input'],
            output_names=['seg_logits', 'pose_heatmaps'],
            # ë°°ì¹˜ ì‚¬ì´ì¦ˆëŠ” ê°€ë³€(dynamic)ìœ¼ë¡œ ë‘ê±°ë‚˜ ê³ ì •í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„  1ë¡œ ê³ ì • ì¶”ì²œ(RT ì„±ëŠ¥ ìµœì í™”)
            dynamic_axes={'input': {0: 'batch_size'}, 'seg_logits': {0: 'batch_size'}, 'pose_heatmaps': {0: 'batch_size'}},
            opset_version=13
        )
        print(f"   âœ… ONNX ì¶”ì¶œ ì™„ë£Œ: {onnx_path}")
    except Exception as e:
        print(f"âŒ ONNX ë³€í™˜ ì‹¤íŒ¨: {e}")
        sys.exit(1)

def build_engine(onnx_path, engine_path):
    print(f"ðŸš€ [Step 2] ONNX -> TensorRT Engine ë¹Œë“œ ì‹œìž‘...")
    
    # CUDA í™˜ê²½ ì„¤ì • (í•„ìš” ì‹œ)
    try:
        from src.utils.cuda_helper import setup_cuda_environment
        setup_cuda_environment()
    except:
        pass

    TRT_LOGGER = trt.Logger(trt.Logger.INFO)
    builder = trt.Builder(TRT_LOGGER)
    
    # Explicit Batch í”Œëž˜ê·¸ ì„¤ì •
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    config = builder.create_builder_config()
    parser = trt.OnnxParser(network, TRT_LOGGER)

    # ONNX íŒŒì‹±
    if not os.path.exists(onnx_path):
        print(f"âŒ ONNX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {onnx_path}")
        sys.exit(1)

    with open(onnx_path, 'rb') as model:
        if not parser.parse(model.read()):
            print("âŒ ONNX íŒŒì‹± ì‹¤íŒ¨")
            for error in range(parser.num_errors):
                print(parser.get_error(error))
            sys.exit(1)

    # ìµœì í™” í”„ë¡œíŒŒì¼ ì„¤ì • (ìž…ë ¥ í¬ê¸° ê³ ì •: 960x544)
    # TensorRT Shape: (Batch, Channel, Height, Width)
    input_shape = (1, 3, TARGET_H, TARGET_W)
    
    profile = builder.create_optimization_profile()
    profile.set_shape("input", input_shape, input_shape, input_shape)
    config.add_optimization_profile(profile)

    # ë©”ëª¨ë¦¬ í’€ ì„¤ì • (4GB)
    try:
        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 32)
    except AttributeError:
        config.max_workspace_size = 1 << 32

    # FP16 ê°€ì† í™œì„±í™” (RTX 3060 ì§€ì›)
    if builder.platform_has_fast_fp16:
        config.set_flag(trt.BuilderFlag.FP16)
        print("   âœ¨ FP16 ê³ ì† ì—°ì‚° ëª¨ë“œ í™œì„±í™”")

    # ì—”ì§„ ë¹Œë“œ
    print("   â³ ì—”ì§„ ë¹Œë“œ ì¤‘... (ì•½ 1~2ë¶„ ì†Œìš”)")
    serialized_engine = builder.build_serialized_network(network, config)

    if serialized_engine is None:
        print("âŒ ì—”ì§„ ë¹Œë“œ ì‹¤íŒ¨")
        sys.exit(1)

    with open(engine_path, "wb") as f:
        f.write(serialized_engine)
    print(f"   âœ… ì—”ì§„ ì €ìž¥ ì™„ë£Œ: {engine_path}")

def main():
    print("========================================================")
    print("   MUSE Student Model Optimization Tool")
    print("   (High-Fidelity Mode: 960x544)")
    print("========================================================")
    
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    model_dir = os.path.join(base_dir, "assets", "models", "personal")
    
    # ì—¬ëŸ¬ í”„ë¡œíŒŒì¼ì„ ìˆœíšŒí•˜ë©° ë³€í™˜í•˜ë„ë¡ í™•ìž¥ ê°€ëŠ¥í•˜ì§€ë§Œ, ì¼ë‹¨ ê¸°ë³¸ íŒŒì¼ëª… ê¸°ì¤€
    # ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ì¸ìžê°’ìœ¼ë¡œ íŒŒì¼ëª…ì„ ë°›ì•„ì•¼ í•¨
    
    pth_path = os.path.join(model_dir, "student_model_final.pth")
    onnx_path = os.path.join(model_dir, "student_model.onnx")
    engine_path = os.path.join(model_dir, "student_model.engine")
    
    # 1. Export ONNX
    export_onnx(pth_path, onnx_path)
    
    # 2. Build TensorRT Engine
    build_engine(onnx_path, engine_path)
    
    print("\nðŸŽ‰ ë³€í™˜ ì™„ë£Œ! ì´ì œ 'tools/run_muse.py'ë¥¼ ì‹¤í–‰í•˜ë©´ ê³ í™”ì§ˆ ì¶”ë¡ ì´ ìž‘ë™í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()