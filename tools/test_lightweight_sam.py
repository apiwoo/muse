# Project MUSE - test_lightweight_sam.py
# (C) 2025 MUSE Corp. All rights reserved.
# Purpose: Real-time Teacher Combination Test (ViTPose + SAM 2.1 Teacher)
# "ViTPoseê°€ ëˆˆ(Eye)ì´ ë˜ì–´ì£¼ê³ , SAM 2.1(Teacher)ê°€ ì†(Hand)ì´ ë˜ì–´ ì˜ë¼ëƒ…ë‹ˆë‹¤."

import cv2
import numpy as np
import sys
import os
import time
import torch
import traceback

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
current_file = os.path.abspath(__file__)
root_dir = os.path.dirname(os.path.dirname(current_file))
sys.path.append(root_dir)
sys.path.append(os.path.join(root_dir, "src"))

# CUDA ì„¤ì •
try:
    from utils.cuda_helper import setup_cuda_environment
    setup_cuda_environment()
except ImportError:
    pass

# ëª¨ë“ˆ ë¡œë“œ
try:
    from ai.tracking.vitpose_trt import VitPoseTrt
    import sam2
    from sam2.build_sam import build_sam2
    from sam2.sam2_image_predictor import SAM2ImagePredictor
    from hydra import initialize_config_dir
    from hydra.core.global_hydra import GlobalHydra
except ImportError as e:
    print(f"[ERROR] í•„ìˆ˜ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)

def apply_mask_overlay(image, mask, color=(0, 255, 0), alpha=0.5):
    """ë§ˆìŠ¤í¬ ì˜ì—­ì— ìƒ‰ìƒì„ ì…í˜€ì„œ ì˜¤ë²„ë ˆì´"""
    if mask is None: return image
    
    mask = mask.astype(bool)
    overlay = image.copy()
    overlay[mask] = np.array(color, dtype=np.uint8)
    
    return cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)

def main():
    print("========================================================")
    print("   MUSE Real-time Teacher Test (ViTPose + SAM 2.1 Large)")
    print("========================================================")

    # 1. ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    # (1) ViTPose (Pose)
    engine_path = os.path.join(root_dir, "assets", "models", "tracking", "vitpose_huge.engine")
    if not os.path.exists(engine_path):
        print("âŒ ViTPose Engine íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ğŸ‘‰ 'python tools/trt_converter.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    # (2) SAM 2.1 Teacher (Large) - [Modified]
    # ê°€ì¥ ì •í™•ë„ê°€ ë†’ì€ ìµœì‹  ëª¨ë¸ (SAM 2.1 Hiera Large)
    sam2_checkpoint = os.path.join(root_dir, "assets", "models", "segment_anything", "sam2.1_hiera_large.pt")
    
    # Config ì„¤ì • (SAM 2.1) - [Fixed]
    # ëª¨ë¸ ë²„ì „ê³¼ Config ë²„ì „ì„ 2.1ë¡œ ì¼ì¹˜ì‹œí‚´
    sam2_config_dir = os.path.join(root_dir, "assets", "sam2_configs", "sam2.1")
    sam2_config_name = "sam2.1_hiera_l.yaml" 

    if not os.path.exists(sam2_checkpoint):
        print("âŒ SAM 2.1 Large ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ğŸ‘‰ 'python tools/download_models.py'ë¥¼ ì‹¤í–‰í•´ì„œ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    # 2. ëª¨ë¸ ë¡œë“œ
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ Device: {device}")

    # [Load ViTPose]
    print("â³ [1/2] Loading ViTPose (TensorRT)...")
    try:
        pose_model = VitPoseTrt(engine_path)
    except Exception as e:
        print(f"âŒ ViTPose ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # [Load SAM 2.1 Large]
    print(f"â³ [2/2] Loading SAM 2.1 Large (Most Accurate)...")
    if GlobalHydra.instance().is_initialized():
        GlobalHydra.instance().clear()

    try:
        with initialize_config_dir(config_dir=sam2_config_dir, version_base="1.2"):
            # í™•ì¥ìë¥¼ ëº€ ì´ë¦„ìœ¼ë¡œ ë¹Œë“œ ì‹œë„ (Hydra íŠ¹ì„±)
            cfg_name = sam2_config_name.replace(".yaml", "")
            sam2_model = build_sam2(cfg_name, sam2_checkpoint, device=device)
            predictor = SAM2ImagePredictor(sam2_model)
    except Exception as e:
        print(f"âŒ SAM 2 ë¡œë“œ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return

    print("âœ… ëª¨ë“  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ.")

    # 3. ì¹´ë©”ë¼ ì‹¤í–‰
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    print("\nğŸ¥ [Start] Loop ì‹œì‘ (Press 'q' to quit)")
    
    prev_time = time.time()
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        loop_start = time.time()

        # -----------------------------------------------------------
        # [Step A] ViTPose: ì‚¬ëŒ ìœ„ì¹˜ ì°¾ê¸°
        # -----------------------------------------------------------
        kpts = pose_model.inference(frame)
        
        box_prompt = None
        has_person = False

        if kpts is not None:
            # ì‹ ë¢°ë„ 0.4 ì´ìƒì¸ í‚¤í¬ì¸íŠ¸ë§Œ í•„í„°ë§
            valid_kpts = kpts[kpts[:, 2] > 0.4]
            
            if len(valid_kpts) > 3: # ì ì´ 3ê°œ ì´ìƒ ë³´ì—¬ì•¼ ì‚¬ëŒìœ¼ë¡œ ì¸ì •
                has_person = True
                
                # Bounding Box ê³„ì‚° (ì—¬ìœ  ê³µê°„ Padding ì¶”ê°€)
                x_min = np.min(valid_kpts[:, 0])
                x_max = np.max(valid_kpts[:, 0])
                y_min = np.min(valid_kpts[:, 1])
                y_max = np.max(valid_kpts[:, 1])
                
                # ë°•ìŠ¤ë¥¼ ì¡°ê¸ˆ ë” í¬ê²Œ ì¡ì•„ì„œ(Padding) SAMì´ ì‚¬ëŒ ì „ì²´ë¥¼ ì˜ ì¡ë„ë¡ ìœ ë„
                pad = 20
                h, w = frame.shape[:2]
                box_prompt = np.array([
                    max(0, x_min - pad), 
                    max(0, y_min - pad), 
                    min(w, x_max + pad), 
                    min(h, y_max + pad)
                ])

        # -----------------------------------------------------------
        # [Step B] SAM 2: ì°¾ì€ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë°€ ë¶„ë¦¬
        # -----------------------------------------------------------
        mask_final = None
        
        if has_person and box_prompt is not None:
            # 1. ì´ë¯¸ì§€ ì¸ì½”ë”© (Large ëª¨ë¸ì€ ì—¬ê¸°ì„œ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            predictor.set_image(frame_rgb)
            
            # 2. ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ë¡œ ë§ˆìŠ¤í¬ ì˜ˆì¸¡
            masks, scores, _ = predictor.predict(
                box=box_prompt,
                multimask_output=False # ê°€ì¥ í™•ì‹¤í•œ ë§ˆìŠ¤í¬ 1ê°œë§Œ ìš”ì²­
            )
            mask_final = masks[0]

        # -----------------------------------------------------------
        # [Step C] ì‹œê°í™”
        # -----------------------------------------------------------
        display = frame.copy()
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë…¸ë€ìƒ‰)
        if box_prompt is not None:
            x1, y1, x2, y2 = box_prompt.astype(int)
            cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 255), 2)
            cv2.putText(display, "ViTPose Detection", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

        # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ (ì´ˆë¡ìƒ‰)
        if mask_final is not None:
            display = apply_mask_overlay(display, mask_final, color=(0, 255, 0), alpha=0.4)
            
            # ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
            contours, _ = cv2.findContours(mask_final.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(display, contours, -1, (0, 255, 0), 2)

        # FPS ê³„ì‚°
        curr_time = time.time()
        fps = 1 / (curr_time - prev_time)
        prev_time = curr_time
        
        infer_time = (time.time() - loop_start) * 1000
        
        # [Modified] Info Text Update
        info_text = f"FPS: {fps:.1f} | Latency: {infer_time:.1f}ms | Model: SAM 2.1 Large"
        cv2.rectangle(display, (0, 0), (650, 40), (0, 0, 0), -1)
        cv2.putText(display, info_text, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        cv2.imshow("MUSE Teacher Test", display)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()