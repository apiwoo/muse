# Project MUSE - test_sam.py (Interactive Mode)
# (C) 2025 MUSE Corp. All rights reserved.
# Purpose: SAM (Segment Anything Model) Point-Prompt Demo
# "í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ë°°ê²½ ë‚ ë¦¬ê¸° (Prompt-based Segmentation)"

import os
import sys
import cv2
import numpy as np
import torch
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    # [í•µì‹¬ ë³€ê²½] AutomaticGenerator ëŒ€ì‹  Predictorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # PredictorëŠ” ì‚¬ìš©ìì˜ 'íŒíŠ¸(ì , ë°•ìŠ¤)'ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ë…€ì„ì…ë‹ˆë‹¤.
    from segment_anything import sam_model_registry, SamPredictor
except ImportError:
    print("âŒ 'segment_anything' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ì „ì—­ ë³€ìˆ˜ (ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ìš©)
click_point = None
clicked = False

def mouse_callback(event, x, y, flags, param):
    global click_point, clicked
    if event == cv2.EVENT_LBUTTONDOWN:
        click_point = np.array([x, y])
        clicked = True
        print(f"ğŸ–±ï¸ í´ë¦­ ì¢Œí‘œ ìˆ˜ì‹ : ({x}, {y})")

def apply_background_removal(image, mask):
    """
    ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ì»¬ëŸ¬ë¡œ ë‚¨ê¸°ê³ , ë°°ê²½ì€ í‘ë°±(ë˜ëŠ” ê²€ì€ìƒ‰)ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ê°•ì¡°
    """
    # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥ (True/False -> 0/1 -> 0/255)
    mask_3ch = np.stack([mask] * 3, axis=-1)
    
    # 1. ì „ê²½ (ì‚¬ëŒ): ë§ˆìŠ¤í¬ê°€ Trueì¸ ë¶€ë¶„ì€ ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
    foreground = np.where(mask_3ch, image, 0)
    
    # 2. ë°°ê²½ (ë‚˜ë¨¸ì§€): ê²€ì€ìƒ‰ìœ¼ë¡œ ë‚ ë ¤ë²„ë¦¬ê¸° (í¬ë¡œë§ˆí‚¤ íš¨ê³¼)
    # background = np.zeros_like(image) 
    
    # (ì˜µì…˜) ë°°ê²½ì„ ì•„ì˜ˆ ì—†ì• ì§€ ì•Šê³  íë¦¿í•˜ê²Œ ë³´ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
    # background = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # background = cv2.cvtColor(background, cv2.COLOR_GRAY2BGR) // 0.3
    
    # í•©ì„±
    result = foreground # + background.astype(np.uint8)
    return result

def main():
    print("========================================================")
    print("   MUSE Interactive Segmentation (SAM ViT-Huge)")
    print("========================================================")
    print("   1. ì›¹ìº ì´ ì¼œì§€ë©´ 'SPACE'ë¥¼ ëˆŒëŸ¬ í™”ë©´ì„ ìº¡ì²˜(Freeze)í•˜ì„¸ìš”.")
    print("   2. ë©ˆì¶˜ í™”ë©´ì—ì„œ ë³¸ì¸(ë˜ëŠ” ì›í•˜ëŠ” ë¬¼ì²´)ì„ 'í´ë¦­'í•˜ì„¸ìš”.")
    print("   3. SAMì´ í´ë¦­ëœ ë¬¼ì²´ë§Œ ì¸ì‹í•´ì„œ ë°°ê²½ì„ ë‚ ë ¤ë²„ë¦½ë‹ˆë‹¤.")
    print("========================================================")

    # 1. ëª¨ë¸ ì„¤ì •
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    MODEL_PATH = os.path.join(BASE_DIR, "assets", "models", "segment_anything", "sam_vit_h_4b8939.pth")

    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {MODEL_PATH}")
        return

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ Device: {device}")

    # 2. ëª¨ë¸ ë¡œë”©
    print("â³ SAM ëª¨ë¸(ViT-Huge) ë¡œë”© ì¤‘... (ë¬´ê±°ìš´ ëª¨ë¸ì…ë‹ˆë‹¤)")
    sam = sam_model_registry["vit_h"](checkpoint=MODEL_PATH)
    sam.to(device=device)
    
    # [í•µì‹¬] Predictor ì´ˆê¸°í™”
    predictor = SamPredictor(sam)
    print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ. (Interactive Mode)")

    # 3. ì¹´ë©”ë¼ ì„¤ì •
    cap = cv2.VideoCapture(1)
    if not cap.isOpened(): cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    # ìœˆë„ìš° ë° ë§ˆìš°ìŠ¤ ì½œë°± ì„¤ì •
    window_name = "MUSE - Interactive SAM"
    cv2.namedWindow(window_name)
    cv2.setMouseCallback(window_name, mouse_callback)

    global clicked
    
    while True:
        # ------------------------------------------------
        # [Mode 1] Live Camera Loop (ì´¬ì˜ ëŒ€ê¸°)
        # ------------------------------------------------
        print("\nğŸ¥ [Live Mode] SPACEë¥¼ ëˆŒëŸ¬ ìº¡ì²˜í•˜ì„¸ìš”.")
        captured_frame = None
        
        while True:
            ret, frame = cap.read()
            if not ret: break
            
            # ê°€ì´ë“œ í…ìŠ¤íŠ¸
            display = frame.copy()
            cv2.putText(display, "Live View - Press SPACE to Capture", (30, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            cv2.imshow(window_name, display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                cap.release()
                cv2.destroyAllWindows()
                return
            elif key == ord(' '): # ìŠ¤í˜ì´ìŠ¤ë°”
                captured_frame = frame
                break
        
        # ------------------------------------------------
        # [Mode 2] Image Encoding (ì„ ìƒë‹˜ì˜ ìƒê° ì‹œê°„)
        # ------------------------------------------------
        print("ğŸ“¸ ìº¡ì²˜ë¨! SAMì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤... (Encoding)")
        
        # SAMì€ RGBë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤.
        frame_rgb = cv2.cvtColor(captured_frame, cv2.COLOR_BGR2RGB)
        
        t0 = time.time()
        # [í•µì‹¬] ì´ë¯¸ì§€ ì „ì²´ë¥¼ í•œ ë²ˆ ì½ì–´ì„œ 'íŠ¹ì§•(Embedding)'ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        # ì´ ê³¼ì •ì€ ë¬´ê²ì§€ë§Œ(ì•½ 0.5~1ì´ˆ), í•œ ë²ˆë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
        predictor.set_image(frame_rgb)
        t1 = time.time()
        print(f"âœ… ì¸ì½”ë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {t1 - t0:.2f}ì´ˆ).")
        print("ğŸ‘‰ ì´ì œ í™”ë©´ ì† ì›í•˜ëŠ” ë¬¼ì²´ë¥¼ 'í´ë¦­'í•˜ì„¸ìš”!")

        # ------------------------------------------------
        # [Mode 3] Interaction Loop (í´ë¦­ ëŒ€ê¸°)
        # ------------------------------------------------
        clicked = False # ìƒíƒœ ì´ˆê¸°í™”
        
        while True:
            display = captured_frame.copy()
            cv2.putText(display, "Click Object / Press R to Retry", (30, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            
            # ë§ˆìš°ìŠ¤ í´ë¦­ì´ ê°ì§€ë˜ë©´ ì‹¤í–‰
            if clicked:
                # 1. ì…ë ¥ ì¢Œí‘œ ì¤€ë¹„
                input_point = np.array([click_point])
                input_label = np.array([1]) # 1ì€ 'ì´ê±°ì•¼(Foreground)', 0ì€ 'ì´ê±° ì•„ëƒ(Background)'
                
                print(f"âœ¨ [Prompt] ì¢Œí‘œ {input_point} ì¶”ë¡  ìš”ì²­...")
                
                # 2. ë§ˆìŠ¤í¬ ì˜ˆì¸¡ (Decoder ì‹¤í–‰ - ë§¤ìš° ë¹ ë¦„)
                # ì¸ì½”ë”©ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆìŠ¤í¬ë§Œ ë±‰ì–´ëƒ…ë‹ˆë‹¤.
                masks, scores, logits = predictor.predict(
                    point_coords=input_point,
                    point_labels=input_label,
                    multimask_output=True, # ì• ë§¤í•  ê²½ìš° 3ê°€ì§€ í›„ë³´ë¥¼ ì¤ë‹ˆë‹¤.
                )
                
                # 3. ê°€ì¥ ì ìˆ˜(IoU)ê°€ ë†’ì€ ë§ˆìŠ¤í¬ ì„ íƒ
                best_idx = np.argmax(scores)
                best_mask = masks[best_idx]
                
                print(f"   -> ì™„ë£Œ! (Score: {scores[best_idx]:.2f})")
                
                # 4. ê²°ê³¼ ì‹œê°í™” (ë°°ê²½ ë‚ ë¦¬ê¸°)
                result_image = apply_background_removal(captured_frame, best_mask)
                
                # ê²°ê³¼ì°½ ë„ìš°ê¸°
                cv2.imshow("MUSE - Result", result_image)
                print("   -> 'MUSE - Result' ì°½ì„ í™•ì¸í•˜ì„¸ìš”.")
                print("   -> (ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ê²°ê³¼ì°½ì´ ë‹«í™ë‹ˆë‹¤)")
                cv2.waitKey(0)
                cv2.destroyWindow("MUSE - Result")
                
                clicked = False # ë‹¤ì‹œ í´ë¦­ ëŒ€ê¸°
                print("   -> ë‹¤ë¥¸ ë¬¼ì²´ë¥¼ í´ë¦­í•˜ê±°ë‚˜, 'R'ì„ ëˆŒëŸ¬ ë‹¤ì‹œ ì°ìœ¼ì„¸ìš”.")

            cv2.imshow(window_name, display)
            key = cv2.waitKey(10) & 0xFF
            
            if key == ord('r'): # ì¬ì´¬ì˜
                break
            elif key == ord('q'):
                cap.release()
                cv2.destroyAllWindows()
                return

if __name__ == "__main__":
    main()