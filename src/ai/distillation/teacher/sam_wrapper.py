# Project MUSE - sam_wrapper.py
# Teacher: SAM 2 (Segment Anything 2) Video Predictor Wrapper
# (C) 2025 MUSE Corp. All rights reserved.

import os
import torch
import numpy as np
import cv2
import sys

# SAM 2 Imports
try:
    from sam2.build_sam import build_sam2_video_predictor
except ImportError:
    print("âŒ SAM 2 library not found. Please run 'pip install git+https://github.com/facebookresearch/segment-anything-2.git'")
    sys.exit(1)

class Sam2VideoWrapper:
    def __init__(self, model_root):
        """
        SAM 2 Video Predictor Wrapper
        - model_root: assets/models/segment_anything/
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ‘¨â€ğŸ« [Teacher A] SAM 2 (Hiera-Large) Initializing on {self.device}...")

        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        checkpoint = os.path.join(model_root, "sam2_hiera_large.pt")
        # SAM 2 ConfigëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ì— ìˆìŒ (sam2_hiera_l.yaml)
        model_cfg = "sam2_hiera_l.yaml"

        if not os.path.exists(checkpoint):
            raise FileNotFoundError(f"âŒ SAM 2 Checkpoint not found: {checkpoint}")

        try:
            self.predictor = build_sam2_video_predictor(model_cfg, checkpoint, device=self.device)
            print("   âœ… SAM 2 Video Predictor Loaded.")
        except Exception as e:
            print(f"   âŒ SAM 2 Loading Failed: {e}")
            raise e
            
        self.inference_state = None

    def init_state(self, video_path):
        """ë¹„ë””ì˜¤ ì„¸ì…˜ ì´ˆê¸°í™” (ì „ì²´ í”„ë ˆì„ ìºì‹±)"""
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"Video not found: {video_path}")
            
        print(f"   ğŸï¸ SAM 2: Initializing video state for {os.path.basename(video_path)}...")
        # SAM 2ëŠ” ë¹„ë””ì˜¤ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê±°ë‚˜ ì¸ë±ì‹±í•¨
        self.inference_state = self.predictor.init_state(video_path=video_path)

    def add_prompt(self, frame_idx, points=None, labels=None, box=None):
        """
        íŠ¹ì • í”„ë ˆì„ì— íŒíŠ¸(Prompt) ì œê³µ
        - points: [[x, y], ...]
        - labels: [1, 1, ...] (1: Foreground, 0: Background)
        """
        if self.inference_state is None:
            raise RuntimeError("Call init_state() first.")

        # SAM 2 API í˜¸ì¶œ
        _, out_obj_ids, out_mask_logits = self.predictor.add_new_points_or_box(
            inference_state=self.inference_state,
            frame_idx=frame_idx,
            obj_id=1, # Person ID
            points=points,
            labels=labels,
            box=box,
        )
        return out_mask_logits

    def propagate(self):
        """
        ë¹„ë””ì˜¤ ì „ì²´ì— ë§ˆìŠ¤í¬ ì „íŒŒ (Video Segmentation)
        Yields: (frame_idx, obj_ids, mask_logits)
        """
        if self.inference_state is None:
            raise RuntimeError("Call init_state() first.")
            
        print("   ğŸŒŠ SAM 2: Propagating masks across video...")
        for out_frame_idx, out_obj_ids, out_mask_logits in self.predictor.propagate_in_video(self.inference_state):
            yield out_frame_idx, out_obj_ids, out_mask_logits

    def reset(self):
        if self.inference_state is not None:
            self.predictor.reset_state(self.inference_state)
            self.inference_state = None