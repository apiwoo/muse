# Project MUSE - inference.py
# The "Student" Inference Engine: Lightweight & Real-time
# (C) 2025 MUSE Corp. All rights reserved.

import torch
import cv2
import numpy as np
import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ í™•ë³´
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))))

from src.ai.distillation.student.model_arch import MuseStudentModel

class StudentInference:
    def __init__(self, model_path=None):
        """
        [MUSE Student Inference]
        - ì—­í• : í•™ìŠµëœ ê°œì¸í™” ëª¨ë¸(.pth)ì„ ë¡œë“œí•˜ì—¬ ì‹¤ì‹œê°„ ì¶”ë¡  ìˆ˜í–‰
        - ì¶œë ¥: (Segmentation Mask, Pose Keypoints)
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ðŸŽ“ [Student] ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™” (Device: {self.device})")

        # 1. ëª¨ë¸ ì•„í‚¤í…ì²˜ ì¤€ë¹„
        self.model = MuseStudentModel(num_keypoints=17).to(self.device)
        self.model.eval()

        # 2. ê°€ì¤‘ì¹˜ ë¡œë“œ
        if model_path is None:
            # ê¸°ë³¸ ê²½ë¡œ: assets/models/personal/student_model_final.pth
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))
            model_path = os.path.join(base_dir, "assets", "models", "personal", "student_model_final.pth")

        if os.path.exists(model_path):
            try:
                state_dict = torch.load(model_path, map_location=self.device)
                self.model.load_state_dict(state_dict)
                print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {os.path.basename(model_path)}")
                self.is_ready = True
            except Exception as e:
                print(f"   âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.is_ready = False
        else:
            print(f"   âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            print("   -> 'tools/train_student.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµì‹œí‚¤ì„¸ìš”.")
            self.is_ready = False

        # ì¶”ë¡ ìš© ìƒìˆ˜
        self.input_size = (512, 512)
        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(self.device)
        self.std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(self.device)

    def infer(self, frame_bgr):
        """
        :param frame_bgr: (H, W, 3) OpenCV Image
        :return: (mask_binary, keypoints)
            - mask_binary: (H, W) 0 or 255 uint8
            - keypoints: (17, 3) [x, y, conf]
        """
        if not self.is_ready or frame_bgr is None:
            return None, None

        h_orig, w_orig = frame_bgr.shape[:2]

        # 1. Preprocess (Resize & Normalize)
        img_resized = cv2.resize(frame_bgr, self.input_size)
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        
        # To Tensor
        img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0).to(self.device)
        img_tensor = (img_tensor - self.mean) / self.std

        # 2. Inference
        with torch.no_grad():
            pred_seg, pred_pose = self.model(img_tensor)
            
            # --- Output 1: Segmentation ---
            # Sigmoid & Threshold
            mask_prob = torch.sigmoid(pred_seg)
            mask_tensor = (mask_prob > 0.5).float().squeeze().cpu().numpy()
            
            # Resize back to original
            mask_uint8 = (mask_tensor * 255).astype(np.uint8)
            mask_final = cv2.resize(mask_uint8, (w_orig, h_orig), interpolation=cv2.INTER_NEAREST)
            
            # --- Output 2: Pose ---
            # Heatmap -> Coordinates
            heatmaps = pred_pose.squeeze().cpu().numpy() # (17, 128, 128)
            keypoints = self._parse_heatmaps(heatmaps, (w_orig, h_orig))

        return mask_final, keypoints

    def _parse_heatmaps(self, heatmaps, original_size):
        """ížˆíŠ¸ë§µì—ì„œ ìµœëŒ€ê°’ ì¢Œí‘œ(x, y)ë¥¼ ì¶”ì¶œí•˜ê³  ì›ë³¸ í¬ê¸°ë¡œ ë³µì›"""
        kpts = []
        w_orig, h_orig = original_size
        _, h_map, w_map = heatmaps.shape
        
        scale_x = w_orig / w_map
        scale_y = h_orig / h_map

        for i in range(17):
            hm = heatmaps[i]
            # Find max loc
            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(hm)
            
            if max_val > 0.1: # Threshold
                x = max_loc[0] * scale_x
                y = max_loc[1] * scale_y
                kpts.append([x, y, max_val])
            else:
                kpts.append([0, 0, 0.0]) # Not found
                
        return np.array(kpts)